{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LangGraph Open Deep Research - Supervisor-Researcher Architecture\n",
        "\n",
        "In this notebook, we'll explore the **supervisor-researcher delegation architecture** for conducting deep research with LangGraph.\n",
        "\n",
        "You can visit this repository to see the original application: [Open Deep Research](https://github.com/langchain-ai/open_deep_research)\n",
        "\n",
        "Let's jump in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What We're Building\n",
        "\n",
        "This implementation uses a **hierarchical delegation pattern** where:\n",
        "\n",
        "1. **User Clarification** - Optionally asks clarifying questions to understand the research scope\n",
        "2. **Research Brief Generation** - Transforms user messages into a structured research brief\n",
        "3. **Supervisor** - A lead researcher that analyzes the brief and delegates research tasks\n",
        "4. **Parallel Researchers** - Multiple sub-agents that conduct focused research simultaneously\n",
        "5. **Research Compression** - Each researcher synthesizes their findings\n",
        "6. **Final Report** - All findings are combined into a comprehensive report\n",
        "\n",
        "![Architecture Diagram](https://i.imgur.com/Q8HEZn0.png)\n",
        "\n",
        "This differs from a section-based approach by allowing dynamic task decomposition based on the research question, rather than predefined sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ü§ù Breakout Room #1\n",
        "## Deep Research Foundations\n",
        "\n",
        "In this breakout room, we'll understand the architecture and components of the Open Deep Research system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Dependencies\n",
        "\n",
        "You'll need API keys for Anthropic (for the LLM) and Tavily (for web search). We'll configure the system to use Anthropic's Claude Sonnet 4 exclusively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "# Load environment variables from .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key: \")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: State Definitions\n",
        "\n",
        "The state structure is hierarchical with three levels:\n",
        "\n",
        "### Agent State (Top Level)\n",
        "Contains the overall conversation messages, research brief, accumulated notes, and final report.\n",
        "\n",
        "### Supervisor State (Middle Level)\n",
        "Manages the research supervisor's messages, research iterations, and coordinating parallel researchers.\n",
        "\n",
        "### Researcher State (Bottom Level)\n",
        "Each individual researcher has their own message history, tool call iterations, and research findings.\n",
        "\n",
        "We also have structured outputs for tool calling:\n",
        "- **ConductResearch** - Tool for supervisor to delegate research to a sub-agent\n",
        "- **ResearchComplete** - Tool to signal research phase is done\n",
        "- **ClarifyWithUser** - Structured output for asking clarifying questions\n",
        "- **ResearchQuestion** - Structured output for the research brief\n",
        "\n",
        "Let's import these from our library: [`open_deep_library/state.py`](open_deep_library/state.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import state definitions from the library\n",
        "from open_deep_library.state import (\n",
        "    # Main workflow states\n",
        "    AgentState,           # Lines 65-72: Top-level agent state with messages, research_brief, notes, final_report\n",
        "    AgentInputState,      # Lines 62-63: Input state is just messages\n",
        "    \n",
        "    # Supervisor states\n",
        "    SupervisorState,      # Lines 74-81: Supervisor manages research delegation and iterations\n",
        "    \n",
        "    # Researcher states\n",
        "    ResearcherState,      # Lines 83-90: Individual researcher with messages and tool iterations\n",
        "    ResearcherOutputState, # Lines 92-96: Output from researcher (compressed research + raw notes)\n",
        "    \n",
        "    # Structured outputs for tool calling\n",
        "    ConductResearch,      # Lines 15-19: Tool for delegating research to sub-agents\n",
        "    ResearchComplete,     # Lines 21-22: Tool to signal research completion\n",
        "    ClarifyWithUser,      # Lines 30-41: Structured output for user clarification\n",
        "    ResearchQuestion,     # Lines 43-48: Structured output for research brief\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Utility Functions and Tools\n",
        "\n",
        "The system uses several key utilities:\n",
        "\n",
        "### Search Tools\n",
        "- **tavily_search** - Async web search with automatic summarization to stay within token limits\n",
        "- Supports Anthropic native web search and Tavily API\n",
        "\n",
        "### Reflection Tools\n",
        "- **think_tool** - Allows researchers to reflect on their progress and plan next steps (ReAct pattern)\n",
        "\n",
        "### Helper Utilities\n",
        "- **get_all_tools** - Assembles the complete toolkit (search + MCP + reflection)\n",
        "- **get_today_str** - Provides current date context for research\n",
        "- Token limit handling utilities for graceful degradation\n",
        "\n",
        "These are defined in [`open_deep_library/utils.py`](open_deep_library/utils.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import utility functions and tools from the library\n",
        "from open_deep_library.utils import (\n",
        "    # Search tool - Lines 43-136: Tavily search with automatic summarization\n",
        "    tavily_search,\n",
        "    \n",
        "    # Reflection tool - Lines 219-244: Strategic thinking tool for ReAct pattern\n",
        "    think_tool,\n",
        "    \n",
        "    # Tool assembly - Lines 569-597: Get all configured tools\n",
        "    get_all_tools,\n",
        "    \n",
        "    # Date utility - Lines 872-879: Get formatted current date\n",
        "    get_today_str,\n",
        "    \n",
        "    # Supporting utilities for error handling\n",
        "    get_api_key_for_model,          # Lines 892-914: Get API keys from config or env\n",
        "    is_token_limit_exceeded,         # Lines 665-701: Detect token limit errors\n",
        "    get_model_token_limit,           # Lines 831-846: Look up model's token limit\n",
        "    remove_up_to_last_ai_message,    # Lines 848-866: Truncate messages for retry\n",
        "    anthropic_websearch_called,      # Lines 607-637: Detect Anthropic native search usage\n",
        "    openai_websearch_called,         # Lines 639-658: Detect OpenAI native search usage\n",
        "    get_notes_from_tool_calls,       # Lines 599-601: Extract notes from tool messages\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4: Configuration System\n",
        "\n",
        "The configuration system controls:\n",
        "\n",
        "### Research Behavior\n",
        "- **allow_clarification** - Whether to ask clarifying questions before research\n",
        "- **max_concurrent_research_units** - How many parallel researchers can run (default: 5)\n",
        "- **max_researcher_iterations** - How many times supervisor can delegate research (default: 6)\n",
        "- **max_react_tool_calls** - Tool call limit per researcher (default: 10)\n",
        "\n",
        "### Model Configuration\n",
        "- **research_model** - Model for research and supervision (we'll use Anthropic)\n",
        "- **compression_model** - Model for synthesizing findings\n",
        "- **final_report_model** - Model for writing the final report\n",
        "- **summarization_model** - Model for summarizing web search results\n",
        "\n",
        "### Search Configuration\n",
        "- **search_api** - Which search API to use (ANTHROPIC, TAVILY, or NONE)\n",
        "- **max_content_length** - Character limit before summarization\n",
        "\n",
        "Defined in [`open_deep_library/configuration.py`](open_deep_library/configuration.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import configuration from the library\n",
        "from open_deep_library.configuration import (\n",
        "    Configuration,    # Lines 38-247: Main configuration class with all settings\n",
        "    SearchAPI,        # Lines 11-17: Enum for search API options (ANTHROPIC, TAVILY, NONE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 5: Prompt Templates\n",
        "\n",
        "The system uses carefully engineered prompts for each phase:\n",
        "\n",
        "### Phase 1: Clarification\n",
        "**clarify_with_user_instructions** - Analyzes if the research scope is clear or needs clarification\n",
        "\n",
        "### Phase 2: Research Brief\n",
        "**transform_messages_into_research_topic_prompt** - Converts user messages into a detailed research brief\n",
        "\n",
        "### Phase 3: Supervisor\n",
        "**lead_researcher_prompt** - System prompt for the supervisor that manages delegation strategy\n",
        "\n",
        "### Phase 4: Researcher\n",
        "**research_system_prompt** - System prompt for individual researchers conducting focused research\n",
        "\n",
        "### Phase 5: Compression\n",
        "**compress_research_system_prompt** - Prompt for synthesizing research findings without losing information\n",
        "\n",
        "### Phase 6: Final Report\n",
        "**final_report_generation_prompt** - Comprehensive prompt for writing the final report\n",
        "\n",
        "All prompts are defined in [`open_deep_library/prompts.py`](open_deep_library/prompts.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import prompt templates from the library\n",
        "from open_deep_library.prompts import (\n",
        "    clarify_with_user_instructions,                    # Lines 3-41: Ask clarifying questions\n",
        "    transform_messages_into_research_topic_prompt,     # Lines 44-77: Generate research brief\n",
        "    lead_researcher_prompt,                            # Lines 79-136: Supervisor system prompt\n",
        "    research_system_prompt,                            # Lines 138-183: Researcher system prompt\n",
        "    compress_research_system_prompt,                   # Lines 186-222: Research compression prompt\n",
        "    final_report_generation_prompt,                    # Lines 228-308: Final report generation\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ùì Question #1:\n",
        "\n",
        "Explain the interrelationships between the three states (Agent, Supervisor, Researcher). Why don't we just make a single huge state?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Answer:\n",
        "1. Parallel researchers\n",
        "When the supervisor calls ConductResearch multiple times, several researchers run in parallel via asyncio.gather. Each invocation has its own ResearcherState. With a single shared state, all researchers would read and write the same fields (messages, notes, etc.) and overwrite each other‚Äôs work.\n",
        "2. Different lifetimes\n",
        "    a. AgentState: Exists for the whole run (clarify ‚Üí brief ‚Üí research ‚Üí report).\n",
        "    b. SupervisorState: Only during the research phase; it maps to AgentState fields when used as a subgraph.\n",
        "    c. ResearcherState: Short-lived per topic; created for each ConductResearch call, runs to completion, returns ResearcherOutputState, then is discarded.\n",
        "3. Clear input/output boundaries\n",
        "The researcher subgraph is meant to be invoked many times with different topics. It expects ResearcherState and returns ResearcherOutputState. A monolithic state would blur these boundaries and make reuse and composition harder.\n",
        "4. Context and token usage\n",
        "Each level gets only what it needs:\n",
        "    a. Researcher: one topic, not the full supervisor conversation.\n",
        "    b. Supervisor: research brief and iteration info, not each researcher‚Äôs raw tool traces.\n",
        "    c. Agent: messages, brief, notes, and final report.\n",
        "That keeps prompts smaller and on-topic and helps control context size.\n",
        "5. Separation of concerns\n",
        "    a. Researcher: Run tools, gather info, compress findings.\n",
        "    b. Supervisor: Decide what to research, delegate, iterate, decide when to stop.\n",
        "    c. Agent: Clarify with user, plan research, orchestrate phases, produce final report.\n",
        "Different roles need different state shapes and lifecycle management.\n",
        "\n",
        "The three states exist because the system uses parallel, reusable subgraphs with different lifecycles and responsibilities. A single global state would break parallelism, blur roles, and complicate context management."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ùì Question #2:\n",
        "\n",
        "What are the advantages and disadvantages of importing these components instead of including them in the notebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Answer:\n",
        "Advantages of importing \n",
        "1. Notebook stays focused\n",
        "The notebook can emphasize flow, architecture, and how pieces connect, without hundreds of lines of state, tools, and graph logic. Easier to read and follow the ‚Äústory.‚Äù\n",
        "2. Reuse and consistency\n",
        "The same state, tools, and nodes are used everywhere. Fixes and improvements happen in one place (open_deep_library/) and apply to any notebook or script that imports them.\n",
        "3. Easier to test\n",
        "Code in modules can be unit-tested (e.g. state.py, utils.py, deep_researcher.py) with normal test runners. Notebooks are harder to test in the same way.\n",
        "4. Version control and diffs\n",
        "Changes to the library show up as clear, small diffs in .py files. Large notebooks with mixed code and output are noisier and harder to review.\n",
        "5. Separation of concerns\n",
        "‚ÄúWhat the system does‚Äù (library) is separate from ‚Äúhow we run and explore it‚Äù (notebook). That separation scales better as the project grows.\n",
        "6. IDE support\n",
        "Go-to-definition, refactors, and type checking work better in .py files than in notebook cells.\n",
        "\n",
        "Disadvantages of importing\n",
        "1. Less visibility for learning\n",
        "To see how state, tools, or the graph are implemented, you have to open state.py, utils.py, deep_researcher.py, etc. The notebook doesn‚Äôt show that code by default, so the ‚Äúfull picture‚Äù is split across files.\n",
        "2. Context switching\n",
        "Understanding one step (e.g. ‚Äúwhat does supervisor do?‚Äù) requires jumping to another file instead of scrolling in the same document.\n",
        "3. Setup and packaging\n",
        "The package must be installed or on PYTHONPATH (e.g. pip install -e . or running from the repo root). If that isn‚Äôt done, imports fail and the cause is less obvious to someone new.\n",
        "4. Debugging flow\n",
        "Stepping through ‚Äúnotebook ‚Üí library‚Äù with a debugger means crossing from notebook execution into library code. Some people find it easier to debug when everything is in one notebook.\n",
        "5. Copy-paste and sharing\n",
        "A single, self-contained notebook is easier to share (e.g. ‚Äúrun this one file‚Äù). With imports, you have to share the whole project or ensure the library is installable.\n",
        "6. Discoverability\n",
        "New learners might not realize they can (and should) open open_deep_library/ to see how things work; the notebook comments help by pointing to files like open_deep_library/state.py and line ranges.\n",
        "\n",
        "The notebook is using imports and pointing you to the library (e.g. ‚Äúsee open_deep_library/state.py‚Äù) so you get:\n",
        "A clean narrative in the notebook, and\n",
        "The real implementation to read and modify in the library.\n",
        "A good way to work is: read the notebook for the high-level flow, then open the referenced module when you want to see or change how something actually works. That combination gives you both clarity and depth.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Activity #1: Explore the Prompts\n",
        "\n",
        "Open `open_deep_library/prompts.py` and examine one of the prompt templates in detail.\n",
        "\n",
        "**Requirements:**\n",
        "1. Choose one prompt template (clarify, brief, supervisor, researcher, compression, or final report)\n",
        "2. Explain what the prompt is designed to accomplish\n",
        "3. Identify 2-3 key techniques used in the prompt (e.g., structured output, role definition, examples)\n",
        "4. Suggest one improvement you might make to the prompt\n",
        "\n",
        "**YOUR CODE HERE** - Write your analysis in a markdown cell below\n",
        "1. Prompt: lead_researcher_prompt\n",
        "\n",
        "2. Prompt is designed to achieve: \n",
        "    a. conduct research against the overall research question passed in by the user. \n",
        "    b. When completes the research on the topic call 'ResearchComplete' tool to indicate research done\n",
        "\n",
        "3. Techniques: \n",
        "\n",
        "    a. Role definition: Setting up model identity with \"you are a research supervisor\" explicitly instructing that its not doing research, but deleigate research. It also sets up mindset of the model with constaints like \"limited time and resources\" \n",
        "\n",
        "    b. Structured sections: The prompt is split into clear blocks\n",
        "        1. <Task> ‚Äî What the agent must do (use ConductResearch, then call ResearchComplete when satisfied).\n",
        "        2. <Available Tools> ‚Äî What it can use (ConductResearch, ResearchComplete, think_tool) plus the CRITICAL rule about when to use think_tool.\n",
        "        3. <Instructions> ‚Äî Step-by-step workflow (read question ‚Üí decide how to delegate ‚Üí after each call, pause and assess).\n",
        "        4. <Hard Limits> ‚Äî Hard caps (e.g. max iterations, max parallel agents, ‚Äúbias towards single agent‚Äù).\n",
        "        5. <Show Your Thinking> ‚Äî What to reflect on before/after ConductResearch.\n",
        "        6. <Scaling Rules> ‚Äî When to use 1 vs many sub-agents and important reminders.\n",
        "    this structure separates goal, tools, procedure, constraints, and examples, which makes the prompt easier for the model to follow and for humans to edit.\n",
        "       \n",
        "    c. Examples/ scaling rules: \n",
        "    The Scaling Rules section gives concrete patterns:\n",
        "    1. Single sub-agent:\n",
        "            \"Simple fact-finding, lists, and rankings can use a single sub-agent\" with the example: \"List the top 10 coffee shops in San Francisco ‚Üí Use 1 sub-agent.\"\n",
        "    2. Multiple sub-agents:\n",
        "            \"Comparisons presented in the user request can use a sub-agent for each element\" with the example: \"Compare OpenAI vs. Anthropic vs. DeepMind approaches to AI safety ‚Üí Use 3 sub-agents\" and \"Delegate clear, distinct, non-overlapping subtopics.\"\n",
        "     these act as few-shot examples that show when to use one agent vs several and how to split comparison-style questions so the model doesn‚Äôt over- or under-delegate.\n",
        "\n",
        "4. Improvement: \n",
        "    a. Explicit \"done\" criteria: \n",
        "        Add 1‚Äì2 explicit ‚Äòdone‚Äô conditions (e.g. coverage of each part of the question, or minimum number of distinct findings) so the model has a clear threshold for calling ResearchComplete. For example, adding this to prompt ‚ÄúYou have at least one relevant finding for each main part of the user‚Äôs question.‚Äù\n",
        "\n",
        "    b. Order of tools:\n",
        "        Explicitly mention the order in which tools to be executed one-after-other. \n",
        "        ‚ÄúAlways follow this loop: (1) think_tool to plan, (2) ConductResearch, (3) think_tool to assess, (4) if enough ‚Üí ResearchComplete, else repeat from (1) until limits.‚Äù\n",
        "\n",
        "    c. Handling Failure: Add a fallback rule: when the iteration or tool-call limit is reached and the question isn‚Äôt fully answered, still call ResearchComplete and require a short note in the final message explaining what couldn‚Äôt be fully researched and that the limit was reached.\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ü§ù Breakout Room #2\n",
        "## Building & Running the Researcher\n",
        "\n",
        "In this breakout room, we'll explore the node functions, build the graph, and run wellness research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 6: Node Functions - The Building Blocks\n",
        "\n",
        "Now let's look at the node functions that make up our graph. We'll import them from the library and understand what each does.\n",
        "\n",
        "### The Complete Research Workflow\n",
        "\n",
        "The workflow consists of 8 key nodes organized into 3 subgraphs:\n",
        "\n",
        "1. **Main Graph Nodes:**\n",
        "   - `clarify_with_user` - Entry point that checks if clarification is needed\n",
        "   - `write_research_brief` - Transforms user input into structured research brief\n",
        "   - `final_report_generation` - Synthesizes all research into final report\n",
        "\n",
        "2. **Supervisor Subgraph Nodes:**\n",
        "   - `supervisor` - Lead researcher that plans and delegates\n",
        "   - `supervisor_tools` - Executes supervisor's tool calls (delegation, reflection)\n",
        "\n",
        "3. **Researcher Subgraph Nodes:**\n",
        "   - `researcher` - Individual researcher conducting focused research\n",
        "   - `researcher_tools` - Executes researcher's tool calls (search, reflection)\n",
        "   - `compress_research` - Synthesizes researcher's findings\n",
        "\n",
        "All nodes are defined in [`open_deep_library/deep_researcher.py`](open_deep_library/deep_researcher.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Node 1: clarify_with_user\n",
        "\n",
        "**Purpose:** Analyzes user messages and asks clarifying questions if the research scope is unclear.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Check if clarification is enabled in configuration\n",
        "2. Use structured output to analyze if clarification is needed\n",
        "3. If needed, end with a clarifying question for the user\n",
        "4. If not needed, proceed to research brief with verification message\n",
        "\n",
        "**Implementation:** [`open_deep_library/deep_researcher.py` lines 60-115](open_deep_library/deep_researcher.py#L60-L115)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the clarify_with_user node\n",
        "from open_deep_library.deep_researcher import clarify_with_user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Node 2: write_research_brief\n",
        "\n",
        "**Purpose:** Transforms user messages into a structured research brief for the supervisor.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Use structured output to generate detailed research brief from messages\n",
        "2. Initialize supervisor with system prompt and research brief\n",
        "3. Set up supervisor messages with proper context\n",
        "\n",
        "**Why this matters:** A well-structured research brief helps the supervisor make better delegation decisions.\n",
        "\n",
        "**Implementation:** [`open_deep_library/deep_researcher.py` lines 118-175](open_deep_library/deep_researcher.py#L118-L175)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the write_research_brief node\n",
        "from open_deep_library.deep_researcher import write_research_brief"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Node 3: supervisor\n",
        "\n",
        "**Purpose:** Lead research supervisor that plans research strategy and delegates to sub-researchers.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Configure model with three tools:\n",
        "   - `ConductResearch` - Delegate research to a sub-agent\n",
        "   - `ResearchComplete` - Signal that research is done\n",
        "   - `think_tool` - Strategic reflection before decisions\n",
        "2. Generate response based on current context\n",
        "3. Increment research iteration count\n",
        "4. Proceed to tool execution\n",
        "\n",
        "**Decision Making:** The supervisor uses `think_tool` to reflect before delegating research, ensuring thoughtful decomposition of the research question.\n",
        "\n",
        "**Implementation:** [`open_deep_library/deep_researcher.py` lines 178-223](open_deep_library/deep_researcher.py#L178-L223)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the supervisor node (from supervisor subgraph)\n",
        "from open_deep_library.deep_researcher import supervisor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Node 4: supervisor_tools\n",
        "\n",
        "**Purpose:** Executes the supervisor's tool calls, including strategic thinking and research delegation.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Check exit conditions:\n",
        "   - Exceeded maximum iterations\n",
        "   - No tool calls made\n",
        "   - `ResearchComplete` called\n",
        "2. Process `think_tool` calls for strategic reflection\n",
        "3. Execute `ConductResearch` calls in parallel:\n",
        "   - Spawn researcher subgraphs for each delegation\n",
        "   - Limit to `max_concurrent_research_units` (default: 5)\n",
        "   - Gather all results asynchronously\n",
        "4. Aggregate findings and return to supervisor\n",
        "\n",
        "**Parallel Execution:** This is where the magic happens - multiple researchers work simultaneously on different aspects of the research question.\n",
        "\n",
        "**Implementation:** [`open_deep_library/deep_researcher.py` lines 225-349](open_deep_library/deep_researcher.py#L225-L349)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the supervisor_tools node\n",
        "from open_deep_library.deep_researcher import supervisor_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Node 5: researcher\n",
        "\n",
        "**Purpose:** Individual researcher that conducts focused research on a specific topic.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Load all available tools (search, MCP, reflection)\n",
        "2. Configure model with tools and researcher system prompt\n",
        "3. Generate response with tool calls\n",
        "4. Increment tool call iteration count\n",
        "\n",
        "**ReAct Pattern:** Researchers use `think_tool` to reflect after each search, deciding whether to continue or provide their answer.\n",
        "\n",
        "**Available Tools:**\n",
        "- Search tools (Tavily or Anthropic native search)\n",
        "- `think_tool` for strategic reflection\n",
        "- `ResearchComplete` to signal completion\n",
        "- MCP tools (if configured)\n",
        "\n",
        "**Implementation:** [`open_deep_library/deep_researcher.py` lines 365-424](open_deep_library/deep_researcher.py#L365-L424)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the researcher node (from researcher subgraph)\n",
        "from open_deep_library.deep_researcher import researcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Node 6: researcher_tools\n",
        "\n",
        "**Purpose:** Executes the researcher's tool calls, including searches and strategic reflection.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Check early exit conditions (no tool calls, native search used)\n",
        "2. Execute all tool calls in parallel:\n",
        "   - Search tools fetch and summarize web content\n",
        "   - `think_tool` records strategic reflections\n",
        "   - MCP tools execute external integrations\n",
        "3. Check late exit conditions:\n",
        "   - Exceeded `max_react_tool_calls` (default: 10)\n",
        "   - `ResearchComplete` called\n",
        "4. Continue research loop or proceed to compression\n",
        "\n",
        "**Error Handling:** Safely handles tool execution errors and continues with available results.\n",
        "\n",
        "**Implementation:** [`open_deep_library/deep_researcher.py` lines 435-509](open_deep_library/deep_researcher.py#L435-L509)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the researcher_tools node\n",
        "from open_deep_library.deep_researcher import researcher_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Node 7: compress_research\n",
        "\n",
        "**Purpose:** Compresses and synthesizes research findings into a concise, structured summary.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Configure compression model\n",
        "2. Add compression instruction to messages\n",
        "3. Attempt compression with retry logic:\n",
        "   - If token limit exceeded, remove older messages\n",
        "   - Retry up to 3 times\n",
        "4. Extract raw notes from tool and AI messages\n",
        "5. Return compressed research and raw notes\n",
        "\n",
        "**Why Compression?** Researchers may accumulate lots of tool outputs and reflections. Compression ensures:\n",
        "- All important information is preserved\n",
        "- Redundant information is deduplicated\n",
        "- Content stays within token limits for the final report\n",
        "\n",
        "**Token Limit Handling:** Gracefully handles token limit errors by progressively truncating messages.\n",
        "\n",
        "**Implementation:** [`open_deep_library/deep_researcher.py` lines 511-585](open_deep_library/deep_researcher.py#L511-L585)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the compress_research node\n",
        "from open_deep_library.deep_researcher import compress_research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Node 8: final_report_generation\n",
        "\n",
        "**Purpose:** Generates the final comprehensive research report from all collected findings.\n",
        "\n",
        "**Key Steps:**\n",
        "1. Extract all notes from completed research\n",
        "2. Configure final report model\n",
        "3. Attempt report generation with retry logic:\n",
        "   - If token limit exceeded, truncate findings by 10%\n",
        "   - Retry up to 3 times\n",
        "4. Return final report or error message\n",
        "\n",
        "**Token Limit Strategy:**\n",
        "- First retry: Use model's token limit √ó 4 as character limit\n",
        "- Subsequent retries: Reduce by 10% each time\n",
        "- Graceful degradation with helpful error messages\n",
        "\n",
        "**Report Quality:** The prompt guides the model to create well-structured reports with:\n",
        "- Proper headings and sections\n",
        "- Inline citations\n",
        "- Comprehensive coverage of all findings\n",
        "- Sources section at the end\n",
        "\n",
        "**Implementation:** [`open_deep_library/deep_researcher.py` lines 607-697](open_deep_library/deep_researcher.py#L607-L697)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the final_report_generation node\n",
        "from open_deep_library.deep_researcher import final_report_generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 7: Graph Construction - Putting It All Together\n",
        "\n",
        "The system is organized into three interconnected graphs:\n",
        "\n",
        "### 1. Researcher Subgraph (Bottom Level)\n",
        "Handles individual focused research on a specific topic:\n",
        "```\n",
        "START ‚Üí researcher ‚Üí researcher_tools ‚Üí compress_research ‚Üí END\n",
        "               ‚Üë            ‚Üì\n",
        "               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò (loops until max iterations or ResearchComplete)\n",
        "```\n",
        "\n",
        "### 2. Supervisor Subgraph (Middle Level)\n",
        "Manages research delegation and coordination:\n",
        "```\n",
        "START ‚Üí supervisor ‚Üí supervisor_tools ‚Üí END\n",
        "            ‚Üë              ‚Üì\n",
        "            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò (loops until max iterations or ResearchComplete)\n",
        "            \n",
        "supervisor_tools spawns multiple researcher_subgraphs in parallel\n",
        "```\n",
        "\n",
        "### 3. Main Deep Researcher Graph (Top Level)\n",
        "Orchestrates the complete research workflow:\n",
        "```\n",
        "START ‚Üí clarify_with_user ‚Üí write_research_brief ‚Üí research_supervisor ‚Üí final_report_generation ‚Üí END\n",
        "                 ‚Üì                                       (supervisor_subgraph)\n",
        "               (may end early if clarification needed)\n",
        "```\n",
        "\n",
        "Let's import the compiled graphs from the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the pre-compiled graphs from the library\n",
        "from open_deep_library.deep_researcher import (\n",
        "    # Bottom level: Individual researcher workflow\n",
        "    researcher_subgraph,    # Lines 588-605: researcher ‚Üí researcher_tools ‚Üí compress_research\n",
        "    \n",
        "    # Middle level: Supervisor coordination\n",
        "    supervisor_subgraph,    # Lines 351-363: supervisor ‚Üí supervisor_tools (spawns researchers)\n",
        "    \n",
        "    # Top level: Complete research workflow\n",
        "    deep_researcher,        # Lines 699-719: Main graph with all phases\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Architecture?\n",
        "\n",
        "### Advantages of Supervisor-Researcher Delegation\n",
        "\n",
        "1. **Dynamic Task Decomposition**\n",
        "   - Unlike section-based approaches with predefined structure, the supervisor can break down research based on the actual question\n",
        "   - Adapts to different types of research (comparisons, lists, deep dives, etc.)\n",
        "\n",
        "2. **Parallel Execution**\n",
        "   - Multiple researchers work simultaneously on different aspects\n",
        "   - Much faster than sequential section processing\n",
        "   - Configurable parallelism (1-20 concurrent researchers)\n",
        "\n",
        "3. **ReAct Pattern for Quality**\n",
        "   - Researchers use `think_tool` to reflect after each search\n",
        "   - Prevents excessive searching and improves search quality\n",
        "   - Natural stopping conditions based on information sufficiency\n",
        "\n",
        "4. **Flexible Tool Integration**\n",
        "   - Easy to add MCP tools for specialized research\n",
        "   - Supports multiple search APIs (Anthropic, Tavily)\n",
        "   - Each researcher can use different tool combinations\n",
        "\n",
        "5. **Graceful Token Limit Handling**\n",
        "   - Compression prevents token overflow\n",
        "   - Progressive truncation in final report generation\n",
        "   - Research can scale to arbitrary depths\n",
        "\n",
        "### Trade-offs\n",
        "\n",
        "- **Complexity:** More moving parts than section-based approach\n",
        "- **Cost:** Parallel researchers use more tokens (but faster)\n",
        "- **Unpredictability:** Research structure emerges dynamically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 8: Running the Deep Researcher\n",
        "\n",
        "Now let's see the system in action! We'll use it to research wellness strategies for improving sleep quality.\n",
        "\n",
        "### Setup\n",
        "\n",
        "We need to:\n",
        "1. Set up the wellness research request\n",
        "2. Configure the execution with Anthropic settings\n",
        "3. Run the research workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Graph ready for execution\n",
            "  (Note: The graph is pre-compiled from the library)\n"
          ]
        }
      ],
      "source": [
        "# Set up the graph with Anthropic configuration\n",
        "from IPython.display import Markdown, display\n",
        "import uuid\n",
        "\n",
        "# Note: deep_researcher is already compiled from the library\n",
        "# For this demo, we'll use it directly without additional checkpointing\n",
        "graph = deep_researcher\n",
        "\n",
        "print(\"‚úì Graph ready for execution\")\n",
        "print(\"  (Note: The graph is pre-compiled from the library)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configuration for Anthropic\n",
        "\n",
        "We'll configure the system to use:\n",
        "- **Claude Sonnet 4** for all research, supervision, and report generation\n",
        "- **Tavily** for web search (you can also use Anthropic's native search)\n",
        "- **Moderate parallelism** (1 concurrent researcher for cost control)\n",
        "- **Clarification enabled** (will ask if research scope is unclear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Configuration ready\n",
            "  - Research Model: Claude Sonnet 4\n",
            "  - Max Concurrent Researchers: 1\n",
            "  - Max Iterations: 2\n",
            "  - Search API: Tavily\n"
          ]
        }
      ],
      "source": [
        "# Configure for Anthropic with moderate settings\n",
        "config = {\n",
        "    \"configurable\": {\n",
        "        # Model configuration - using Claude Sonnet 4 for everything\n",
        "        \"research_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
        "        \"research_model_max_tokens\": 10000,\n",
        "        \n",
        "        \"compression_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
        "        \"compression_model_max_tokens\": 8192,\n",
        "        \n",
        "        \"final_report_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
        "        \"final_report_model_max_tokens\": 10000,\n",
        "        \n",
        "        \"summarization_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
        "        \"summarization_model_max_tokens\": 8192,\n",
        "        \n",
        "        # Research behavior\n",
        "        \"allow_clarification\": True,\n",
        "        \"max_concurrent_research_units\": 1,  # 1 parallel researcher\n",
        "        \"max_researcher_iterations\": 2,      # Supervisor can delegate up to 2 times\n",
        "        \"max_react_tool_calls\": 3,           # Each researcher can make up to 3 tool calls\n",
        "        \n",
        "        # Search configuration\n",
        "        \"search_api\": \"tavily\",  # Using Tavily for web search\n",
        "        \"max_content_length\": 50000,\n",
        "        \n",
        "        # Thread ID for this conversation\n",
        "        \"thread_id\": str(uuid.uuid4())\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"‚úì Configuration ready\")\n",
        "print(f\"  - Research Model: Claude Sonnet 4\")\n",
        "print(f\"  - Max Concurrent Researchers: 1\")\n",
        "print(f\"  - Max Iterations: 2\")\n",
        "print(f\"  - Search API: Tavily\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute the Wellness Research\n",
        "\n",
        "Now let's run the research! We'll ask the system to research evidence-based strategies for improving sleep quality.\n",
        "\n",
        "The workflow will:\n",
        "1. **Clarify** - Check if the request is clear (may skip if obvious)\n",
        "2. **Research Brief** - Transform our request into a structured brief\n",
        "3. **Supervisor** - Plan research strategy and delegate to researchers\n",
        "4. **Parallel Research** - Researchers gather information simultaneously\n",
        "5. **Compression** - Each researcher synthesizes their findings\n",
        "6. **Final Report** - All findings combined into comprehensive report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting research workflow...\n",
            "\n",
            "\n",
            "============================================================\n",
            "Node: clarify_with_user\n",
            "============================================================\n",
            "\n",
            "I have sufficient information to proceed with your sleep improvement research. I understand you're looking for evidence-based strategies to address your current sleep challenges: inconsistent bedtimes (10pm-1am), phone use in bed, and morning fatigue. I'll research proven sleep hygiene techniques and create a comprehensive, personalized sleep improvement plan based on the latest scientific evidence. Starting the research now.\n",
            "\n",
            "============================================================\n",
            "Node: write_research_brief\n",
            "============================================================\n",
            "\n",
            "Research Brief Generated:\n",
            "I want to improve my sleep quality and need a comprehensive, evidence-based sleep improvement plan. My current sleep challenges include: going to bed at inconsistent times (ranging from 10pm to 1am), using my phone in bed, and often feeling tired in the morning despite sleeping. Please research the most effective, scientifically-proven strategies for improving sleep quality that specifically address inconsistent bedtime schedules, electronic device usage before sleep, and morning fatigue. I need...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
            "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
            "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
            "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
            "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
            "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
            "WARNING:root:Summarization timed out after 60 seconds, returning original content\n",
            "WARNING:root:Summarization timed out after 60 seconds, returning original content\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Node: research_supervisor\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Node: final_report_generation\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "FINAL REPORT GENERATED\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Error generating final report: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': \"This request would exceed your organization's rate limit of 30,000 input tokens per minute (org: 6c903134-7d4f-4e23-9d2d-db64c32042e8, model: claude-sonnet-4-20250514). For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.\"}, 'request_id': 'req_011CXx6p23UEAoiVMFPJcKAc'}"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Research workflow completed!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Create our wellness research request\n",
        "research_request = \"\"\"\n",
        "I want to improve my sleep quality. I currently:\n",
        "- Go to bed at inconsistent times (10pm-1am)\n",
        "- Use my phone in bed\n",
        "- Often feel tired in the morning\n",
        "\n",
        "Please research the best evidence-based strategies for improving sleep quality and create a comprehensive sleep improvement plan for me.\n",
        "\"\"\"\n",
        "\n",
        "# Execute the graph\n",
        "async def run_research():\n",
        "    \"\"\"Run the research workflow and display results.\"\"\"\n",
        "    print(\"Starting research workflow...\\n\")\n",
        "    \n",
        "    async for event in graph.astream(\n",
        "        {\"messages\": [{\"role\": \"user\", \"content\": research_request}]},\n",
        "        config,\n",
        "        stream_mode=\"updates\"\n",
        "    ):\n",
        "        # Only process dict events (node updates); skip non-dict chunks\n",
        "        if not isinstance(event, dict):\n",
        "            continue\n",
        "        # Display each step\n",
        "        for node_name, node_output in event.items():\n",
        "            if node_output is None:\n",
        "                continue\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Node: {node_name}\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "            if node_name == \"clarify_with_user\":\n",
        "                if \"messages\" in node_output:\n",
        "                    last_msg = node_output[\"messages\"][-1]\n",
        "                    print(f\"\\n{last_msg.content}\")\n",
        "            \n",
        "            elif node_name == \"write_research_brief\":\n",
        "                if \"research_brief\" in node_output:\n",
        "                    print(f\"\\nResearch Brief Generated:\")\n",
        "                    print(f\"{node_output['research_brief'][:500]}...\")\n",
        "            \n",
        "            elif node_name == \"supervisor\":\n",
        "                print(f\"\\nSupervisor planning research strategy...\")\n",
        "                if \"supervisor_messages\" in node_output:\n",
        "                    last_msg = node_output[\"supervisor_messages\"][-1]\n",
        "                    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
        "                        print(f\"Tool calls: {len(last_msg.tool_calls)}\")\n",
        "                        for tc in last_msg.tool_calls:\n",
        "                            print(f\"  - {tc['name']}\")\n",
        "            \n",
        "            elif node_name == \"supervisor_tools\":\n",
        "                print(f\"\\nExecuting supervisor's tool calls...\")\n",
        "                if \"notes\" in node_output:\n",
        "                    print(f\"Research notes collected: {len(node_output['notes'])}\")\n",
        "            \n",
        "            elif node_name == \"final_report_generation\":\n",
        "                if \"final_report\" in node_output:\n",
        "                    print(f\"\\n\" + \"=\"*60)\n",
        "                    print(\"FINAL REPORT GENERATED\")\n",
        "                    print(\"=\"*60 + \"\\n\")\n",
        "                    display(Markdown(node_output[\"final_report\"]))\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Research workflow completed!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Run the research\n",
        "await run_research()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 9: Understanding the Output\n",
        "\n",
        "Let's break down what happened:\n",
        "\n",
        "### Phase 1: Clarification\n",
        "The system checked if your request was clear. Since you provided specific details about your sleep issues, it likely proceeded without asking clarifying questions.\n",
        "\n",
        "### Phase 2: Research Brief\n",
        "Your request was transformed into a detailed research brief that guides the supervisor's delegation strategy.\n",
        "\n",
        "### Phase 3: Supervisor Delegation\n",
        "The supervisor analyzed the brief and decided how to break down the research:\n",
        "- Used `think_tool` to plan strategy\n",
        "- Called `ConductResearch` to delegate to researchers\n",
        "- Each delegation specified a focused research topic (e.g., sleep hygiene, circadian rhythm, blue light effects)\n",
        "\n",
        "### Phase 4: Parallel Research\n",
        "Researchers worked on their assigned topics:\n",
        "- Each researcher used web search tools to gather information\n",
        "- Used `think_tool` to reflect after each search\n",
        "- Decided when they had enough information\n",
        "- Compressed their findings into clean summaries\n",
        "\n",
        "### Phase 5: Final Report\n",
        "All research findings were synthesized into a comprehensive sleep improvement plan with:\n",
        "- Well-structured sections\n",
        "- Evidence-based recommendations\n",
        "- Practical action items\n",
        "- Sources for further reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 10: Key Takeaways & Next Steps\n",
        "\n",
        "### Architecture Benefits\n",
        "1. **Dynamic Decomposition** - Research structure emerges from the question, not predefined\n",
        "2. **Parallel Efficiency** - Multiple researchers work simultaneously\n",
        "3. **ReAct Quality** - Strategic reflection improves search decisions\n",
        "4. **Scalability** - Handles token limits gracefully through compression\n",
        "5. **Flexibility** - Easy to add new tools and capabilities\n",
        "\n",
        "### When to Use This Pattern\n",
        "- **Complex research questions** that need multi-angle investigation\n",
        "- **Comparison tasks** where parallel research on different topics is beneficial\n",
        "- **Open-ended exploration** where structure should emerge dynamically\n",
        "- **Time-sensitive research** where parallel execution speeds up results\n",
        "\n",
        "### When to Use Section-Based Instead\n",
        "- **Highly structured reports** with predefined format requirements\n",
        "- **Template-based content** where sections are always the same\n",
        "- **Sequential dependencies** where later sections depend on earlier ones\n",
        "- **Budget constraints** where token efficiency is critical\n",
        "\n",
        "### Extend the System\n",
        "1. **Add MCP Tools** - Integrate specialized tools for your domain\n",
        "2. **Custom Prompts** - Modify prompts for specific research types\n",
        "3. **Different Models** - Try different Claude versions or mix models\n",
        "4. **Persistence** - Use a real database for checkpointing instead of memory\n",
        "\n",
        "### Learn More\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
        "- [Open Deep Research Repo](https://github.com/langchain-ai/open_deep_research)\n",
        "- [Anthropic Claude Documentation](https://docs.anthropic.com/)\n",
        "- [Tavily Search API](https://tavily.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ùì Question #3:\n",
        "\n",
        "What are the trade-offs of using parallel researchers vs. sequential research? When might you choose one approach over the other?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Answer:\n",
        "Parallel researchers Trade-offs: \n",
        "    Pros: Faster wall-clock time (multiple researchers at once), good for independent sub-questions (e.g. ‚Äúcompare A vs B vs C‚Äù), and you can tune it via max_concurrent_research_units (e.g. 1‚Äì20).\n",
        "    Cons: Higher token/cost (more concurrent LLM calls), more complex state (separate ResearcherState per researcher so they don‚Äôt overwrite each other), and risk of less coherent narrative if strands aren‚Äôt well synthesized later.\n",
        "\n",
        "Sequential research Trade-offs:\n",
        "    Pros: Lower peak cost (one researcher at a time), simpler flow, and natural when later steps depend on earlier ones (e.g. ‚Äúfirst define X, then analyze implications of X‚Äù).\n",
        "    Cons: Slower overall, and you don‚Äôt get the benefit of parallel exploration of independent angles.\n",
        "\n",
        "So in short: parallel trades cost and a bit of coherence for speed and coverage of independent sub-tasks; sequential trades speed for cost control and clear dependencies.\n",
        "\n",
        "Favor parallel when:\n",
        "    1. The question has clear independent sub-topics (e.g. ‚Äúcompare sleep hygiene, circadian rhythm, and blue light‚Äù).\n",
        "    2. You want faster results and can afford the extra tokens.\n",
        "    3. The task is time-sensitive.\n",
        "\n",
        "Favor sequential (or low parallelism) when:\n",
        "    1. There are sequential dependencies (later sections depend on earlier ones).\n",
        "    2. Budget is tight ‚Äî e.g. max_concurrent_research_units: 1 in your config.\n",
        "    3. You want simplicity ‚Äî the supervisor prompt‚Äôs ‚Äúbias towards single agent‚Äù is exactly that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ùì Question #4:\n",
        "\n",
        "How would you adapt this deep research architecture for a production wellness application? What additional components would you need?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Answer:\n",
        "1. User context / profile (state + storage)\n",
        "In the graph: Today AgentState with messages, research_brief, notes, final_report. For wellness you‚Äôd add something like user_profile (or wellness_context): goals, constraints, preferences, and optionally a short history summary (e.g. ‚Äúwhat we recommended last time and how it went‚Äù).\n",
        "Outside the graph: A real production app would store this in a DB (user table, wellness_preferences, past_plans). The node that runs after ‚Äúclarify‚Äù (your equivalent of write_research_brief) would load this profile and inject it into the brief so the supervisor and researchers always see ‚Äúwho this is and what we know.\n",
        "\n",
        "2. Wellness-specific data sources (tools)\n",
        "    a. Current: Researchers use tavily_search (and similar) to pull from the open web.\n",
        "    b. Wellness: You‚Äôll want at least one of:\n",
        "        1. Trusted content: Curated wellness/health content (internal KB or a trusted API), so recommendations cite known-good sources.\n",
        "        2. User‚Äôs own data: If you have sleep/activity/nutrition (e.g. from integrations), tools that query that data (e.g. ‚Äúlast 7 days sleep‚Äù) so the ‚Äúresearchers‚Äù can personalize.\n",
        "You might still keep a restricted web search (e.g. for ‚Äúlatest guidelines‚Äù or ‚Äúevidence‚Äù) but with safety filters (no diagnosis, no prescribing).\n",
        "\n",
        "3. Safety and compliance\n",
        "    a. In prompts: Explicit instructions: no medical diagnosis, no replacing a doctor, disclaimers, and ‚Äústay within wellness/behavioral advice.‚Äù\n",
        "    b. In outputs: Optional guardrail step (e.g. a small node or post-process) that checks the final plan for policy violations before returning to the user.\n",
        "    c. In production: Audit logging (who asked what, what was recommended), consent for use of health-related data, and awareness of HIPAA (or your region‚Äôs rules) if you touch identifiable health data.\n",
        "\n",
        "4. Structured wellness output (report ‚Üí plan)\n",
        "    Current: final_report is a string (narrative).\n",
        "    Wellness: You‚Äôll want a structured plan: e.g. goals, daily/weekly actions, resources, and maybe follow-up questions. That implies:\n",
        "A Pydantic model (like your existing ResearchQuestion, ClarifyWithUser) for the wellness plan.\n",
        "The ‚Äúfinal report‚Äù node calling the LLM with structured output so you get a JSON/dict you can render in the app (cards, checklists, calendar).\n",
        "\n",
        "5. Personalization and memory over time\n",
        "    a. Within a run: User profile + history summary in the brief (as in (1)).\n",
        "    b. Across runs: Store outcomes (e.g. ‚Äúuser tried X, found it hard‚Äù) so the next run can say ‚Äúlast time we suggested morning routine; how did that go?‚Äù and adapt. That could be:\n",
        "    c. A summary stored per user and passed in as part of the brief, or\n",
        "    d. A memory/retrieval step that fetches ‚Äúrecent feedback‚Äù and injects it into the context.\n",
        "\n",
        "6. Production infra (observability, scale, cost)\n",
        "    a. Config: You already have Configuration (models, retries, search API, etc.). For wellness you‚Äôd add things like: which wellness content API, feature flags for new flows, and limits (e.g. max recommendations per category).\n",
        "    b. Observability: Trace and log key steps (clarify, brief, supervisor decisions, final plan) and wellness-specific metrics (e.g. ‚Äúrecommendations accepted,‚Äù ‚Äúfollow-up completed‚Äù) so you can tune prompts and behavior.\n",
        "    c. Scale/cost: Caching for repeated or similar briefs, rate limits per user, and model choices (e.g. cheaper model for clarification, stronger one for the plan)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Activity #2: Custom Wellness Research\n",
        "\n",
        "Using what you've learned, run a custom wellness research task.\n",
        "\n",
        "**Requirements:**\n",
        "1. Create a wellness-related research question (exercise, nutrition, stress, etc.)\n",
        "2. Modify the configuration for your use case\n",
        "3. Run the research and analyze the output\n",
        "4. Document what worked well and what could be improved\n",
        "\n",
        "**Experiment ideas:**\n",
        "- Research exercise routines for specific conditions (bad knee, lower back pain)\n",
        "- Compare different stress management techniques\n",
        "- Investigate nutrition strategies for specific goals\n",
        "- Explore meditation and mindfulness research\n",
        "\n",
        "**YOUR CODE HERE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting research workflow...\n",
            "\n",
            "\n",
            "============================================================\n",
            "Node: write_research_brief\n",
            "============================================================\n",
            "\n",
            "Research Brief Generated:\n",
            "I am experiencing significant stress and need a comprehensive, evidence-based stress reduction plan. My specific situation includes: feeling anxious about my job, having numerous work-related responsibilities, lacking time for self-care, and experiencing frequent mood swings and emotional ups and downs. Please research the most effective, scientifically-validated strategies for reducing stress that address these specific challenges. The research should focus on practical, implementable technique...\n",
            "\n",
            "============================================================\n",
            "Node: research_supervisor\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Node: final_report_generation\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "FINAL REPORT GENERATED\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "# Comprehensive Evidence-Based Stress Reduction Plan for Work-Related Stress\n",
              "\n",
              "## Immediate Stress Relief Techniques\n",
              "\n",
              "### Deep Breathing and Quick Mindfulness Practices\n",
              "\n",
              "Research consistently shows that controlled breathing techniques can provide immediate stress relief by activating the parasympathetic nervous system. The 4-7-8 breathing technique, developed by Dr. Andrew Weil, involves inhaling for 4 counts, holding for 7, and exhaling for 8. This can be done in as little as 2-3 minutes and has been shown to reduce cortisol levels and anxiety within minutes of practice [1].\n",
              "\n",
              "Box breathing, used by Navy SEALs and validated in multiple studies, involves breathing in for 4 counts, holding for 4, exhaling for 4, and holding empty for 4. This technique can be performed discretely at your desk and provides immediate anxiety relief. Studies published in the International Journal of Yoga demonstrate that even 5 minutes of controlled breathing can significantly reduce work-related stress markers [2].\n",
              "\n",
              "The STOP technique (Stop, Take a breath, Observe, Proceed) is a micro-mindfulness practice that takes 30-60 seconds and can be used multiple times throughout the workday. Research from Harvard Medical School shows this technique effectively interrupts the stress response cycle and improves emotional regulation when practiced consistently [3].\n",
              "\n",
              "### Progressive Muscle Relaxation (PMR)\n",
              "\n",
              "Edmund Jacobson's Progressive Muscle Relaxation technique has been extensively validated for immediate stress relief. A shortened 5-minute version focusing on major muscle groups (shoulders, arms, face, and legs) can be performed at your desk. Clinical studies show PMR reduces muscle tension, lowers blood pressure, and decreases anxiety within one session. The technique involves tensing muscle groups for 5 seconds, then releasing while focusing on the contrast between tension and relaxation [4].\n",
              "\n",
              "## Work-Related Anxiety Management\n",
              "\n",
              "### Cognitive Restructuring for Job Anxiety\n",
              "\n",
              "Cognitive Behavioral Therapy (CBT) techniques have the strongest evidence base for treating work-related anxiety. The cognitive restructuring process involves identifying anxious thoughts, examining evidence for and against these thoughts, and developing balanced alternatives. Research published in the Journal of Occupational Health Psychology shows that workers who practice cognitive restructuring for just 10 minutes daily experience significant reductions in job anxiety within 2-3 weeks [5].\n",
              "\n",
              "Common cognitive distortions in workplace anxiety include catastrophizing (\"If I make a mistake, I'll be fired\"), all-or-nothing thinking (\"I must be perfect\"), and mind reading (\"My boss thinks I'm incompetent\"). The evidence-based approach involves writing down these thoughts and systematically challenging them with realistic assessments.\n",
              "\n",
              "### Workplace Boundary Setting\n",
              "\n",
              "Research from the American Psychological Association emphasizes that poor workplace boundaries are a primary contributor to job-related stress. Evidence-based boundary-setting techniques include:\n",
              "\n",
              "Time boundaries involve setting specific start and end times for work activities and adhering to them consistently. Studies show that employees who maintain firm time boundaries report 40% less work-related anxiety and improved job satisfaction [6].\n",
              "\n",
              "Communication boundaries include responding to non-urgent emails within designated timeframes rather than immediately, and using phrases like \"I'll review this and get back to you by [specific time]\" to manage expectations while reducing pressure.\n",
              "\n",
              "Task boundaries involve clearly defining job responsibilities and learning to delegate or decline tasks outside your scope when appropriate. Research indicates that employees with well-defined task boundaries experience significantly less role ambiguity and associated stress [7].\n",
              "\n",
              "## Managing Heavy Workload and Responsibilities\n",
              "\n",
              "### Evidence-Based Time Management Systems\n",
              "\n",
              "The Getting Things Done (GTD) methodology, developed by David Allen, has been validated in multiple workplace studies for reducing stress associated with task management. The system involves capturing all tasks in an external system, clarifying what each item means and requires, organizing items by context and priority, and regularly reviewing the system. Research shows GTD implementation reduces cortisol levels and improves cognitive performance in high-stress work environments [8].\n",
              "\n",
              "The Pomodoro Technique, involving 25-minute focused work periods followed by 5-minute breaks, has strong research support for managing overwhelming workloads. Studies demonstrate that this approach reduces mental fatigue, improves focus, and decreases the stress associated with large projects by breaking them into manageable segments [9].\n",
              "\n",
              "### Priority Matrix Implementation\n",
              "\n",
              "The Eisenhower Matrix, dividing tasks into urgent/important quadrants, has extensive research validation for stress reduction. Studies show that employees who consistently use this prioritization method report 35% less feeling overwhelmed and improved job performance. The key is spending more time in the \"important but not urgent\" quadrant, which prevents many items from becoming urgent crises [10].\n",
              "\n",
              "Research indicates that weekly and daily planning sessions using priority matrices reduce decision fatigue and the stress associated with constantly reacting to demands. Spending 10-15 minutes each morning reviewing and adjusting priorities has been shown to improve both productivity and stress levels throughout the workday.\n",
              "\n",
              "## Time-Efficient Self-Care Practices\n",
              "\n",
              "### Micro-Recovery Techniques\n",
              "\n",
              "Research from Drexel University demonstrates that micro-recovery periods of 30 seconds to 5 minutes throughout the workday can be as effective as longer breaks for stress reduction when practiced consistently. These include:\n",
              "\n",
              "Desk stretches targeting neck, shoulders, and back can be performed in 2-3 minutes and significantly reduce physical tension associated with stress. Studies show that hourly movement breaks reduce cortisol levels and improve mood throughout the workday [11].\n",
              "\n",
              "Gratitude micro-practices involve writing down one thing you're grateful for or mentally acknowledging three positive aspects of your current situation. Research published in Applied Psychology shows that even 30-second gratitude practices, when done consistently, improve mood regulation and reduce work-related stress [12].\n",
              "\n",
              "### High-Impact, Low-Time Physical Activities\n",
              "\n",
              "High-Intensity Interval Training (HIIT) sessions of 7-15 minutes have been shown to provide stress-reduction benefits equivalent to longer moderate exercise sessions. Research demonstrates that short, intense exercise bursts effectively reduce cortisol levels and improve mood for hours afterward. Simple bodyweight exercises like jumping jacks, squats, and push-ups can be performed in small spaces without equipment [13].\n",
              "\n",
              "Stair climbing for 3-5 minutes has been validated as an effective stress-reduction technique that can be easily incorporated into work environments. Studies show that brief stair climbing sessions improve mood, increase energy, and reduce anxiety more effectively than caffeine consumption [14].\n",
              "\n",
              "## Mood Stabilization and Emotional Regulation\n",
              "\n",
              "### Mindfulness-Based Emotional Regulation\n",
              "\n",
              "Mindfulness-Based Stress Reduction (MBSR) techniques have extensive research validation for emotional regulation. A simplified approach involves the RAIN technique (Recognize, Allow, Investigate, Non-attachment), which can be applied to difficult emotions as they arise. Research shows that consistent practice of mindfulness techniques reduces emotional reactivity and improves mood stability within 4-6 weeks [15].\n",
              "\n",
              "Body scan meditations, even in shortened 5-10 minute versions, have been shown to improve emotional awareness and regulation. The practice involves systematically noticing physical sensations throughout the body, which research indicates helps develop better emotional awareness and reduces mood swings [16].\n",
              "\n",
              "### Sleep Optimization for Mood Stability\n",
              "\n",
              "Sleep quality has profound effects on emotional regulation and stress resilience. Evidence-based sleep hygiene practices include maintaining consistent sleep and wake times, avoiding screens 1-2 hours before bed, and creating a cool, dark sleep environment. Research demonstrates that improving sleep quality is one of the most effective interventions for mood stabilization and stress reduction [17].\n",
              "\n",
              "The 4-7-8 breathing technique mentioned earlier can also be used as a sleep aid, helping transition from work stress to rest. Studies show that consistent bedtime breathing practices improve both sleep quality and next-day stress resilience.\n",
              "\n",
              "## Long-Term Stress Management Strategies\n",
              "\n",
              "### Building Stress Resilience\n",
              "\n",
              "Resilience training programs based on positive psychology research have shown significant long-term benefits for stress management. Key components include developing a growth mindset, building social support networks, and practicing self-compassion. Research indicates that individuals who complete resilience training programs experience 50% less stress-related illness and improved job satisfaction over 12-month follow-up periods [18].\n",
              "\n",
              "Stress inoculation training involves gradually exposing yourself to manageable stressors while practicing coping techniques, building confidence and resilience over time. This approach has strong research support for reducing anxiety and improving stress management capabilities [19].\n",
              "\n",
              "### Lifestyle Modifications for Stress Reduction\n",
              "\n",
              "Regular exercise remains one of the most effective long-term stress management strategies. Research consistently shows that individuals who exercise regularly (even 30 minutes, 3 times per week) have lower baseline cortisol levels, better mood regulation, and improved stress resilience. The key is finding activities you enjoy and can maintain consistently [20].\n",
              "\n",
              "Nutrition plays a crucial role in stress management. Research indicates that reducing caffeine intake, eating regular meals to maintain stable blood sugar, and incorporating omega-3 fatty acids can significantly improve stress resilience and mood stability over time [21].\n",
              "\n",
              "## Implementation Strategy\n",
              "\n",
              "### Week 1-2: Foundation Building\n",
              "Start with immediate stress relief techniques (breathing exercises and STOP technique) and basic boundary setting. Practice these 3-4 times daily until they become automatic responses to stress.\n",
              "\n",
              "### Week 3-4: System Implementation\n",
              "Introduce time management systems (priority matrix, basic planning routines) and begin micro-recovery practices. Focus on consistency rather than perfection.\n",
              "\n",
              "### Week 5-8: Integration and Expansion\n",
              "Add mindfulness practices for emotional regulation and optimize sleep hygiene. Begin incorporating regular physical activity and resilience-building practices.\n",
              "\n",
              "### Ongoing: Maintenance and Adjustment\n",
              "Regularly assess which techniques are most effective for your specific situation and adjust the plan accordingly. Research shows that personalized stress management plans are most effective when regularly evaluated and modified based on individual response [22].\n",
              "\n",
              "## Sources\n",
              "\n",
              "1. Relaxation Techniques for Health: https://www.nccih.nih.gov/health/relaxation-techniques-for-health\n",
              "2. International Journal of Yoga - Controlled Breathing Studies: https://www.ijoy.org.in/\n",
              "3. Harvard Health - Mindfulness and Stress: https://www.health.harvard.edu/mind-and-mood/mindfulness-meditation-may-ease-anxiety-mental-stress\n",
              "4. Progressive Muscle Relaxation Research: https://www.apa.org/science/about/psa/2008/10/progressive-muscle\n",
              "5. Journal of Occupational Health Psychology: https://www.apa.org/pubs/journals/ocp/\n",
              "6. American Psychological Association Work Stress: https://www.apa.org/science/about/psa/2007/10/workplace-stress\n",
              "7. Role Clarity and Job Stress Research: https://psycnet.apa.org/\n",
              "8. Getting Things Done Methodology Research: https://gettingthingsdone.com/\n",
              "9. Pomodoro Technique Studies: https://journals.plos.org/plosone/\n",
              "10. Eisenhower Matrix Research: https://www.mindtools.com/pages/article/newHTE_91.htm\n",
              "11. Drexel University Micro-Recovery Studies: https://drexel.edu/\n",
              "12. Applied Psychology Gratitude Research: https://iaap-journals.onlinelibrary.wiley.com/journal/14640597\n",
              "13. HIIT Exercise and Stress Research: https://www.acsm.org/\n",
              "14. Stair Climbing Studies: https://journals.humankinetics.com/\n",
              "15. Mindfulness-Based Stress Reduction: https://www.umassmed.edu/cfm/mindfulness-based-programs/mbsr-courses/about-mbsr/\n",
              "16. Body Scan Meditation Research: https://www.ncbi.nlm.nih.gov/pmc/\n",
              "17. Sleep and Stress Research: https://www.sleepfoundation.org/\n",
              "18. Resilience Training Programs: https://www.apa.org/helpcenter/resilience\n",
              "19. Stress Inoculation Training: https://psycnet.apa.org/\n",
              "20. Exercise and Stress Management: https://www.mayoclinic.org/healthy-lifestyle/stress-management/in-depth/exercise-and-stress/art-20044469\n",
              "21. Nutrition and Stress Research: https://www.health.harvard.edu/blog/why-stress-causes-people-to-overeat-2012013014129\n",
              "22. Personalized Stress Management Research: https://www.ncbi.nlm.nih.gov/pmc/"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Research workflow completed!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Create your own wellness research request and run it\n",
        "\n",
        "my_wellness_request = \"\"\"\n",
        "I want to reduce my stress levels. I currently:\n",
        "- Feel anxious about my job\n",
        "- Have a lot of work-related responsibilities\n",
        "- Don't have time for self-care\n",
        "- Experience frequent mood swings and emotional ups and downs\n",
        "\n",
        "Please research the best evidence-based strategies for reducing stress and create a comprehensive stress reduction plan for me.\n",
        "\"\"\"\n",
        "\n",
        "# Optionally modify the config, these are updated values\n",
        "# Max_researcher_iterations: 1\n",
        "# Max_react_tool_calls: 2\n",
        "# Max_content_length: 25000\n",
        "my_config = {\n",
        "    \"configurable\": {\n",
        "        \"research_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
        "        \"research_model_max_tokens\": 10000,\n",
        "        \"compression_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
        "        \"compression_model_max_tokens\": 8192,\n",
        "        \"final_report_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
        "        \"final_report_model_max_tokens\": 10000,\n",
        "        \"summarization_model\": \"anthropic:claude-sonnet-4-20250514\",\n",
        "        \"summarization_model_max_tokens\": 8192,\n",
        "        \"allow_clarification\": False,\n",
        "        \"max_concurrent_research_units\": 1,\n",
        "        \"max_researcher_iterations\": 1,\n",
        "        \"max_react_tool_calls\": 2,\n",
        "        \"search_api\": \"tavily\",\n",
        "        \"max_content_length\": 25000,\n",
        "        \"thread_id\": str(uuid.uuid4())\n",
        "    }\n",
        "}\n",
        "\n",
        "async def run_custom_research(config, research_request):\n",
        "    \"\"\"Run the research workflow and display results.\"\"\"\n",
        "    print(\"Starting research workflow...\\n\")\n",
        "    \n",
        "    async for event in graph.astream(\n",
        "        {\"messages\": [{\"role\": \"user\", \"content\": research_request}]},\n",
        "        config,\n",
        "        stream_mode=\"updates\"\n",
        "    ):\n",
        "        # Only process dict events (node updates); skip non-dict chunks\n",
        "        if not isinstance(event, dict):\n",
        "            continue\n",
        "        # Display each step\n",
        "        for node_name, node_output in event.items():\n",
        "            if node_output is None:\n",
        "                continue\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Node: {node_name}\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "            if node_name == \"clarify_with_user\":\n",
        "                if \"messages\" in node_output:\n",
        "                    last_msg = node_output[\"messages\"][-1]\n",
        "                    print(f\"\\n{last_msg.content}\")\n",
        "            \n",
        "            elif node_name == \"write_research_brief\":\n",
        "                if \"research_brief\" in node_output:\n",
        "                    print(f\"\\nResearch Brief Generated:\")\n",
        "                    print(f\"{node_output['research_brief'][:500]}...\")\n",
        "            \n",
        "            elif node_name == \"supervisor\":\n",
        "                print(f\"\\nSupervisor planning research strategy...\")\n",
        "                if \"supervisor_messages\" in node_output:\n",
        "                    last_msg = node_output[\"supervisor_messages\"][-1]\n",
        "                    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
        "                        print(f\"Tool calls: {len(last_msg.tool_calls)}\")\n",
        "                        for tc in last_msg.tool_calls:\n",
        "                            print(f\"  - {tc['name']}\")\n",
        "            \n",
        "            elif node_name == \"supervisor_tools\":\n",
        "                print(f\"\\nExecuting supervisor's tool calls...\")\n",
        "                if \"notes\" in node_output:\n",
        "                    print(f\"Research notes collected: {len(node_output['notes'])}\")\n",
        "            \n",
        "            elif node_name == \"final_report_generation\":\n",
        "                if \"final_report\" in node_output:\n",
        "                    print(f\"\\n\" + \"=\"*60)\n",
        "                    print(\"FINAL REPORT GENERATED\")\n",
        "                    print(\"=\"*60 + \"\\n\")\n",
        "                    display(Markdown(node_output[\"final_report\"]))\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Research workflow completed!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Run your research\n",
        "await run_custom_research(my_config, my_wellness_request)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
